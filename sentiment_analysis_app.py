# -*- coding: utf-8 -*-
"""Sentiment_Analysis_App.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17UPz44J-9j6kFuIsPVA6lUwi3lOfoj28
"""

import streamlit as st
import joblib
import re
import nltk
from nltk.corpus import stopwords

# Download stopwords once (if needed)
try:
    stop_words = set(stopwords.words('english'))
except LookupError:
    nltk.download('stopwords')
    stop_words = set(stopwords.words('english'))

# Paths to model files
MODEL_PATH = 'models/logistic_model.pkl'
VECTORIZER_PATH = 'models/tfidf_vectorizer.pkl'
LABEL_ENCODER_PATH = 'models/label_encoder.pkl'

# Load model, vectorizer, and label encoder
def load_model():
    model = joblib.load(MODEL_PATH)
    vectorizer = joblib.load(VECTORIZER_PATH)
    le = joblib.load(LABEL_ENCODER_PATH)
    return model, vectorizer, le

lr_model, vectorizer, le = load_model()

# Text preprocessing
def preprocess_text(text):
    text = re.sub(r'<.*?>', ' ', text)          # Remove HTML tags
    text = text.lower()                         # Lowercase
    text = re.sub(r'[^a-z\s]', '', text)       # Remove non-alphabetic characters
    tokens = text.split()                       # Tokenize by whitespace
    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords
    return ' '.join(tokens)

# Predict sentiment
def predict_sentiment(review_text):
    cleaned = preprocess_text(review_text)
    vector = vectorizer.transform([cleaned])
    pred = lr_model.predict(vector)
    return le.inverse_transform(pred)[0]

# Streamlit app interface
st.title("Sentiment Analysis Web App")

user_input = st.text_area("Enter your review here:")

if st.button("Predict Sentiment"):
    if user_input.strip():
        sentiment = predict_sentiment(user_input)
        st.write(f"Predicted Sentiment: **{sentiment.capitalize()}**")
    else:
        st.warning("Please enter a review to analyze.")





